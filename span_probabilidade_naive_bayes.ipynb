{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNxUGzvsJM6VBMtgRZDkbWo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JorgeDanilo/Data_Science/blob/master/span_probabilidade_naive_bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter, defaultdict\n",
        "from machine_learning import split_data, precision, recall, f1_score\n",
        "import math, random, re, glob\n"
      ],
      "metadata": {
        "id": "KbvqV9SiDPgP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes\n",
        "\n",
        "Uma rede social não é muito boa se as pessoas não podem interagir. Assim, a *DataSciencester* tem um recurso popular que permite que os membros enviem mensagens para outros membros. E enquanto a maioria de seus membros são cidadãos responsáveis que enviam apenas mensagens educadas do tipo \"como vai?\", alguns canalhas insistentemente enviam spam a outros membros sobre esquemas de enriquecimento, produtos farmacêuticos sem receita médica e programas de credenciamento de ciência de dados para fins lucrativos. Seus usuários começaram a reclamar e, portanto, o diretor do departamento de mensagens solicitou que você usasse a ciência de dados para descobrir uma maneira de filtrar essas mensagens de spam.\n",
        "\n",
        "## Um filtro de spam realmente bobo\n",
        "\n",
        "Imagine um \"universo\" que consiste em receber uma mensagem escolhida aleatoriamente de todas as mensagens possíveis. Seja $S$ o evento \"a mensagem é spam\" e $V$ é o evento \"a mensagem contém a palavra \"viagra\". Em seguida, o Teorema de Bayes nos diz que a probabilidade de a mensagem ser spam condicionada a conter a palavra \"viagra\" é:\n",
        "\n",
        "$$P(S~|~V) = \\frac{P(V~|~S)~P(S)}{P(V~|~S)~P(S) ~+~ P(V~|~\\neg S)~P(\\neg S)}$$\n",
        "\n",
        "O numerador é a probabilidade de uma mensagem ser spam **e** conter viagra, enquanto o denominador é apenas a probabilidade de uma mensagem conter viagra. Portanto, você pode pensar nesse cálculo como simplesmente representando a proporção de mensagens do viagra que são spam.\n",
        "\n",
        "Se temos uma grande coleção de mensagens que sabemos serem spam, e uma grande coleção de mensagens que sabemos não ser spam, podemos estimar facilmente $P(V~|~S)$ e $P(V~|~\\neg S)$. Se, além disso, assumirmos que qualquer mensagem tem a mesma probabilidade de ser spam ou não spam (de modo que $P(S) = P(\\neg S) = 0.5$), então:\n",
        "\n",
        "$$P(S~|~V) = \\frac{P(V~|~S)~P(S)}{P(V~|~S) ~+~ P(V~|~\\neg S)}$$\n",
        "\n",
        "Por exemplo, se 50% das mensagens de spam tiverem a palavra viagra, mas apenas 1% das mensagens não spam tiverem, a probabilidade de um determinado email contendo viagra ser spam é:\n",
        "\n",
        "$$P(S~|~V) = \\frac{0.5}{0.5 + 0.01} = 98\\%$$ "
      ],
      "metadata": {
        "id": "CDgQ8MjxXyXB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementação\n",
        "\n",
        "Agora temos todas as peças que precisamos para construir nosso classificador. Primeiro, vamos criar uma função simples para transformar as mensagens em palavras distintas. Primeiro, converteremos cada mensagem em minúscula. Para isso, use `re.findall()` para extrair \"palavras\" consistindo de letras, números e apóstrofos; e finalmente use `set()` para obter apenas as palavras distintas:"
      ],
      "metadata": {
        "id": "Z_mqMlnHX5xy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UFIw5_AF8y0F"
      },
      "outputs": [],
      "source": [
        "def tokenize(message):\n",
        "  messsage = message.lower()                        # convert to lowercase\n",
        "  all_words = re.findall(\"[a-z0-9']+\", message)     # extract the words\n",
        "  return set(all_words)                             # remove duplicates"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nossa segunda função contará as palavras de um conjunto de treinamento de mensagens rotuladas. Teremos que retornar um dicionário cujas chaves sejam palavras e cujo valores sejam listas de dois elementos [spam_count, non_spam_count] correspondendo a quantas vezes vimos essas palavras em mensagens de spam e não-spam."
      ],
      "metadata": {
        "id": "jf2MXpjLET_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_words(training_set):\n",
        "  \"\"\"training set consists of pairs (message, is_spam)\"\"\"\n",
        "  counts = defaultdict(lambda: [0, 0])\n",
        "  for message, is_spam in training_set:\n",
        "    for word in tokenize(message):\n",
        "      counts[word][0 if is_spam else 1] += 1\n",
        "  return counts"
      ],
      "metadata": {
        "id": "MpLh7MVw-7xO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nosso próximo passo é transformar essas contagens em probabilidades estimadas usando a suavização descrita anteriormente. Nossa função retornará uma lista de três valores: a palavra, a probabilidade de ver essa palavra em uma mensagem de spam e a probabilidade de ver essa palavra em uma mensagem não-spam:"
      ],
      "metadata": {
        "id": "LAKRZ5jeIGqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word_probabilities(counts, total_spams, total_non_spams, k=0.5):\n",
        "  \"\"\"turn the word_counts int a list of triplets\n",
        "  w, p(w | spam) and p(w | ~ spam) \"\"\"\n",
        "  return [(w,\n",
        "          (spam + k) / (total_spams + 2 * k),\n",
        "          (non_spam + k) / (total_non_spams + 2 * k))\n",
        "          for w, (spam, non_spam) in counts.items()]"
      ],
      "metadata": {
        "id": "32AipjoWIgiC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A última parte é usar essas probabilidades de palavras (e nossas suposições Naive Bayes) para atribuir probabilidades às mensagens:"
      ],
      "metadata": {
        "id": "mjL7UHoHJf7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def spam_probability(word_probs, message):\n",
        "  message_words = tokenize(message)\n",
        "  log_prob_if_spam = log_prob_if_not_spam = 0.0\n",
        "\n",
        "  for word, prob_if_spam, prob_if_not_spam in word_probs:\n",
        "\n",
        "    # for each word in the message.\n",
        "    # add the log probability of seeing it\n",
        "    if word in message_words:\n",
        "      log_prob_if_spam += math.log(prob_if_spam)\n",
        "      log_prob_if_not_spam += math.log(prob_if_not_spam)\n",
        "\n",
        "    # for each word that's not in the message\n",
        "    # add the log probability of _not_ seeing it\n",
        "    else:\n",
        "      log_prob_if_spam += math.log(1.0 - prob_if_spam)\n",
        "      log_prob_if_not_spam += math.log(1.0 - prob_if_not_spam)\n",
        "\n",
        "  prob_if_spam = math.exp(log_prob_if_spam)\n",
        "  prob_if_not_spam = math.exp(log_prob_if_not_spam)\n",
        "  return prob_if_spam / (prob_if_spam + prob_if_not_spam)"
      ],
      "metadata": {
        "id": "IqELjvRqJsEq"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos colocar tudo isso junto em nosso classificador Naive Bayes:"
      ],
      "metadata": {
        "id": "ph4uzMEWLSSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NaiveBayesClassifier:\n",
        "\n",
        "  def __init__(self, k=0.5):\n",
        "    self.k = k\n",
        "    self.word_probs = []\n",
        "\n",
        "  def train(self, training_set):\n",
        "\n",
        "    # count spam and non-spam messages\n",
        "    num_spams = len([is_spam\n",
        "                     for message, is_spam in training_set\n",
        "                     if is_spam])\n",
        "    num_non_spams = len(training_set) - num_spams\n",
        "    \n",
        "    # run training data through our \"pipeline\"\n",
        "    word_counts = count_words(training_set)\n",
        "    self.word_probs = word_probabilities(word_counts,\n",
        "                                         num_spams,\n",
        "                                         num_non_spams,\n",
        "                                         self.k)\n",
        "    \n",
        "  def classify(self, message):\n",
        "    return spam_probability(self.word_probs, message)"
      ],
      "metadata": {
        "id": "C7zOS1wLLX_C"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_subject_data(path):\n",
        "\n",
        "  data = []\n",
        "\n",
        "  subject_regex = re.compile(r\"^Subject:\\s+\")\n",
        "\n",
        "  for fn in glob.glob(path):\n",
        "    is_spam = \"ham\" not in fn\n",
        "\n",
        "    with open(fn, 'r', encoding='ISO-8859-1') as file:\n",
        "      for line in file:\n",
        "        if line.startswith(\"Subject:\"):\n",
        "          subject = subject_regex.sub(\"\", line).strip()\n",
        "          data.append((subject, is_spam))\n",
        "\n",
        "  return data\n"
      ],
      "metadata": {
        "id": "ga-x77ErJ7Xr"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/data/spam/*/*\"\n",
        "data = get_subject_data(path)\n",
        "print(len(data), \"messagens lidas.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbuIYldvOS6o",
        "outputId": "83be3d2b-f3dc-42e8-c4e2-b06ea2c87f2a"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "898 messagens lidas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora a gente pode dividir os dados em conjunto de treino e conjunto de teste, e depois estaremos prontos para executar o classificador"
      ],
      "metadata": {
        "id": "9n9uNHWzRQkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(0)\n",
        "train_data, test_data = split_data(data, 0.75)\n",
        "classifier = NaiveBayesClassifier()\n",
        "classifier.train(train_data)"
      ],
      "metadata": {
        "id": "QPcY3I5mRY5Q"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora vamos ver como nosso modelo se saiu:"
      ],
      "metadata": {
        "id": "C58sz1seRsdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tripplets (subject, actual is_spam, predicted spam probability)\n",
        "classified = [(subject, is_spam, classifier.classify(subject))\n",
        "              for subject, is_spam in test_data]\n",
        "\n",
        "# assume that spam_probability > 0.5 correponds to spam prediction\n",
        "# and count the combinations of (actual is_spam, predicted is_spam)\n",
        "counts = Counter((is_spam, spam_probability > 0.5)\n",
        "                  for _, is_spam, spam_probability in classified)\n",
        "\n",
        "print(counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8vxtiNyRwbI",
        "outputId": "887a9860-4a6b-445c-abd4-5964eb41f2bd"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({(True, True): 111, (False, False): 52, (False, True): 46, (True, False): 6})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tp = counts[(True, True)]\n",
        "fp = counts[(False, True)]\n",
        "tn = counts[(False, False)]\n",
        "fn = counts[(True, False)]"
      ],
      "metadata": {
        "id": "zoZNH-auT1ly"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A nossa precião foi em torno de 71%"
      ],
      "metadata": {
        "id": "uB8C16FIYBU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Precisão: \", precision(tp, fp, fn, tn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwX64rgIUCgy",
        "outputId": "2732c50d-5541-43d1-d23a-ce18eddedcb2"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisão:  0.7070063694267515\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos ver as palavras que mais tem spam"
      ],
      "metadata": {
        "id": "8vjA5zyPYRSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def p_spam_given_word(word_prob):\n",
        "  word, prob_if_spam, prob_if_not_spam = word_prob\n",
        "  return prob_if_spam / (prob_if_spam + prob_if_not_spam)"
      ],
      "metadata": {
        "id": "zJ8Mt-rFYPyW"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = sorted(classifier.word_probs, key=p_spam_given_word)\n",
        "\n",
        "spammiest_words = words[-5:]\n",
        "hammiest_words = words[:5]"
      ],
      "metadata": {
        "id": "ic22_NVTYiLQ"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"spammiest_words\", spammiest_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vm1guRiIYq3x",
        "outputId": "b01bb309-a5a0-426b-d94d-b9613aae8aff"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spammiest_words [('6', 0.02454780361757106, 0.0016778523489932886), ('zzzz', 0.027131782945736434, 0.0016778523489932886), ('ocial', 0.029715762273901807, 0.0016778523489932886), ('5', 0.03488372093023256, 0.0016778523489932886), ('ow', 0.03488372093023256, 0.0016778523489932886)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"hammiest_words\", hammiest_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMYZzdQxYzAb",
        "outputId": "4f3e972e-371e-4dc0-8ca2-bbc2c798e2b8"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hammiest_words [('zzzzteana', 0.0012919896640826874, 0.025167785234899327), ('be', 0.0012919896640826874, 0.015100671140939598), ('ed', 0.0012919896640826874, 0.015100671140939598), ('crash', 0.0012919896640826874, 0.015100671140939598), ('deal', 0.0012919896640826874, 0.015100671140939598)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As palavras mais relacionadas com spam são \"money\", \"systemworks\", \"rates\", \"sale\" e \"year\", todas relacionadas à tentativa de levar as pessoas a comprar coisas. E as palavras mais relacionadas a mensagens não spam são \"spambayes\", \"users\", \"razor\", \"zzzzteana\" e \"sadev\", a maioria das quais parece relacionada à prevenção de spam, curiosamente.\n",
        "\n",
        "### Como poderíamos obter um melhor desempenho?\n",
        "\n",
        "Uma maneira óbvia seria obter mais dados para treinar. Há várias maneiras de melhorar o modelo também. Aqui estão algumas possibilidades que você pode tentar:\n",
        "\n",
        "* Observe o conteúdo da mensagem, não apenas a linha de assunto. Você precisa ter cuidado ao lidar com os cabeçalhos das mensagens.\n",
        "\n",
        "* Nosso classificador leva em conta todas as palavras que aparecem no conjunto de treinamento, mesmo as que aparecem apenas uma vez. Modifique o classificador para aceitar um limiar `min_count` opcional e ignorar os tokens que não aparecem pelo menos essa quantidade de vezes.\n",
        "\n",
        "* O tokenizador não tem noção de palavras semelhantes (por exemplo, \"cheap\" e \"cheapest\"). Modifique o classificador para obter uma função opcional `stemmer` que converta palavras em *classes de equivalência*  de palavras. Por exemplo, uma função `stemmer` realmente simples pode ser:"
      ],
      "metadata": {
        "id": "RduhpCR-ZEc6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FGXsxV_xZEW8"
      }
    }
  ]
}